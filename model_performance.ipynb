{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/msgifsr/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "import sys\n",
    "sys.path=list(set(sys.path))\n",
    "root_dir='/home/ec2-user/SageMaker/sequence-based-recommendation'\n",
    "model_name=\"NARM\"\n",
    "model_path=os.path.join(root_dir,model_name)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "from NARM import metric\n",
    "from NARM.utils import collate_fn\n",
    "from NARM.narm import NARM\n",
    "from NARM.dataset import load_data, RecSysDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NARM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_loader, model,device):\n",
    "    model.eval()\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "    losses=[]\n",
    "    with torch.no_grad():\n",
    "        for seq, target, lens in valid_loader:\n",
    "            seq = seq.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs = model(seq, lens)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(outputs, target)\n",
    "            logits = F.softmax(outputs, dim = 1)\n",
    "            recall, mrr = metric.evaluate(logits, target, k = args.topk)\n",
    "            recalls.append(recall)\n",
    "            mrrs.append(mrr)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_mrr = np.mean(mrrs)\n",
    "    mean_loss=np.mean(losses)\n",
    "    \n",
    "    return mean_recall, mean_mrr, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=100, dataset_path='./YOOCHOOSE_data/yoochoose1_64/', embed_dim=128, hidden_size=128, model_checkpoint='amex_checkpoint.pth', n_items=37484, topk=20)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset_path', default='./YOOCHOOSE_data/yoochoose1_64/', \n",
    "                        help='dataset directory path: datasets/amex/yoochoose1_4/yoochoose1_64')\n",
    "    \n",
    "    parser.add_argument('--n_items', type=int, default=37484, help='number of unique items. 37484 for yoochoose')\n",
    "    parser.add_argument('--batch_size', type=int, default=100, help='input batch size')\n",
    "    parser.add_argument('--hidden_size', type=int, default=128, help='hidden state size of gru module')\n",
    "    parser.add_argument('--embed_dim', type=int, default=128, help='the dimension of item embedding')\n",
    "    parser.add_argument('--topk', type=int, default=20, help='number of top score items selected for calculating recall and mrr metrics')\n",
    "    parser.add_argument(\"--model_checkpoint\", type=str, default=\"amex_checkpoint.pth\") \n",
    "    args,_ = parser.parse_known_args()\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yoochoose1_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 369859\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "training batch                3,699      \n",
      "test batch                    559        \n",
      "\n",
      "Test: Recall@20: 0.6979, MRR@20: 0.2958\n"
     ]
    }
   ],
   "source": [
    "model_name=\"NARM\"\n",
    "\n",
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_64/'\n",
    "args.n_items=37484\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embed_dim=128 \n",
    "args.hidden_size=128\n",
    "args.model_checkpoint='yoochoose1_64_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader = DataLoader(train_data, batch_size = args.batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NARM(args.n_items, args.hidden_size, args.embed_dim, args.batch_size).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v1, mrr_v1,loss_v1 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v1, args.topk, mrr_v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diginetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 719470\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 60858\n",
      "--------------------------------------------------\n",
      "training batch                7,195      \n",
      "test batch                    609        \n",
      "\n",
      "Test: Recall@20: 0.4743, MRR@20: 0.1533\n"
     ]
    }
   ],
   "source": [
    "model_name=\"NARM\"\n",
    "\n",
    "args.dataset_path='./diginetica_data/'\n",
    "args.n_items=43098\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embed_dim=128 \n",
    "args.hidden_size=128\n",
    "args.model_checkpoint='diginetica_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader = DataLoader(train_data, batch_size = args.batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NARM(args.n_items, args.hidden_size, args.embed_dim, args.batch_size).to(device)\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v2, mrr_v2,loss_v2 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v2, args.topk, mrr_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 3536\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 305\n",
      "--------------------------------------------------\n",
      "training batch                111        \n",
      "test batch                    10         \n",
      "\n",
      "Test: Recall@20: 0.6827, MRR@20: 0.4614\n"
     ]
    }
   ],
   "source": [
    "model_name=\"NARM\"\n",
    "\n",
    "args.dataset_path=\"./dataset/amex_explorepoi-poi_category/\"\n",
    "args.n_items=556\n",
    "args.batch_size=32 \n",
    "args.epoch=30 \n",
    "args.embed_dim=256 \n",
    "args.hidden_size=256\n",
    "args.model_checkpoint='amex_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader = DataLoader(train_data, batch_size = args.batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NARM(args.n_items, args.hidden_size, args.embed_dim, args.batch_size).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v3, mrr_v3,loss_v3 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v3, args.topk, mrr_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3b1af_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall@20</th>\n",
       "      <th class=\"col_heading level0 col3\" >MRR@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3b1af_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3b1af_row0_col0\" class=\"data row0 col0\" >NARM</td>\n",
       "      <td id=\"T_3b1af_row0_col1\" class=\"data row0 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_3b1af_row0_col2\" class=\"data row0 col2\" >69.79%</td>\n",
       "      <td id=\"T_3b1af_row0_col3\" class=\"data row0 col3\" >29.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b1af_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3b1af_row1_col0\" class=\"data row1 col0\" >NARM</td>\n",
       "      <td id=\"T_3b1af_row1_col1\" class=\"data row1 col1\" >diginetica</td>\n",
       "      <td id=\"T_3b1af_row1_col2\" class=\"data row1 col2\" >47.43%</td>\n",
       "      <td id=\"T_3b1af_row1_col3\" class=\"data row1 col3\" >15.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b1af_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3b1af_row2_col0\" class=\"data row2 col0\" >NARM</td>\n",
       "      <td id=\"T_3b1af_row2_col1\" class=\"data row2 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_3b1af_row2_col2\" class=\"data row2 col2\" >68.27%</td>\n",
       "      <td id=\"T_3b1af_row2_col3\" class=\"data row2 col3\" >46.14%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcfa2b78d90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df=pd.DataFrame()\n",
    "output_df[\"Model\"]=[\"NARM\"]*3\n",
    "output_df[\"Dataset\"]=[\"yoochoose1_64\",\"diginetica\",\"amex-poi-category\"]\n",
    "output_df[\"Recall@20\"]=[recall_v1,recall_v2,recall_v3]\n",
    "output_df[\"MRR@20\"]=[mrr_v1,mrr_v2,mrr_v3]\n",
    "output_df.style.format({'Recall@20':'{:.2%}','MRR@20':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "sys.path=list(set(sys.path))\n",
    "root_dir='/home/ec2-user/SageMaker/sequence-based-recommendation'\n",
    "old_model_name=\"NARM\"\n",
    "old_model_path=os.path.join(root_dir,old_model_name)\n",
    "sys.path=[x for x in sys.path if x !=old_model_path]\n",
    "\n",
    "model_name=\"SRGNN\"\n",
    "model_path=os.path.join(root_dir,model_name)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "from SRGNN.srgnn import SRGNN\n",
    "from SRGNN.collate import (collate_fn_factory, seq_to_session_graph)\n",
    "from SRGNN import metric\n",
    "from SRGNN.dataset import load_data,RecSysDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(batch, device):\n",
    "    inputs, labels = batch\n",
    "    # inputs, labels = batch\n",
    "    inputs_gpu  = [x.to(device) for x in inputs]\n",
    "    labels_gpu  = labels.to(device)\n",
    "   \n",
    "    return inputs_gpu, labels_gpu \n",
    "\n",
    "def validate(valid_loader, model,device):\n",
    "    model.eval()\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "    losses=[]\n",
    "    with torch.no_grad():\n",
    "        for step, batch in tqdm(enumerate(valid_loader), total=len(valid_loader),position=0,leave=True):\n",
    "            inputs, labels = prepare_batch(batch, device)\n",
    "            outputs = model(*inputs)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(outputs, labels)\n",
    "            # loss = nn.functional.nll_loss(outputs, labels)\n",
    "            logits = F.softmax(outputs, dim = 1)\n",
    "            recall, mrr = metric.evaluate(logits, labels, k = args.topk)\n",
    "            recalls.append(recall)\n",
    "            mrrs.append(mrr)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_mrr = np.mean(mrrs)\n",
    "    mean_loss=np.mean(losses)\n",
    "    \n",
    "    return mean_recall, mean_mrr, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=100, dataset_dir='../YOOCHOOSE_data/yoochoose1_64/', embedding_dim=100, feat_drop=0.1, model_checkpoint='amex_checkpoint.pth', n_items=37484, num_layers=1, num_workers=0, seed=101, topk=20, valid_split=0.1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        '--dataset-dir', default='../YOOCHOOSE_data/yoochoose1_64/', help='the dataset directory'\n",
    "    )\n",
    "    parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "            help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "    parser.add_argument(\n",
    "    '--batch-size', type=int, default=100, help='the batch size for training'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('--n_items', type=int, default=37484, help='number of unique items. 37484 for yoochoose')\n",
    "    parser.add_argument('--embedding-dim', type=int, default=100, help='the embedding size')\n",
    "    parser.add_argument('--num-layers', type=int, default=1, help='the number of layers')\n",
    "    parser.add_argument('--feat-drop', type=float, default=0.1, help='the dropout ratio for features')\n",
    "    parser.add_argument(\n",
    "    '--valid-split',\n",
    "    type=float,\n",
    "    default=0.1,\n",
    "    help='the fraction for the validation set',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--num-workers',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help='the number of processes to load the input graphs',\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--topk', \n",
    "        type=int, \n",
    "        default=20, \n",
    "        help='number of top score items selected for calculating recall and mrr metrics',\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\"--model_checkpoint\", type=str, default=\"amex_checkpoint.pth\")\n",
    "    \n",
    "    args,_= parser.parse_known_args()\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yoochoose1_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 369859\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           3,699      \n",
      "test mini-batch               559        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 559/559 [00:18<00:00, 29.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.7074, MRR@20: 0.3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"SRGNN\"\n",
    "\n",
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_64/'\n",
    "args.n_items=37484\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=128\n",
    "args.num_layers=1\n",
    "args.model_checkpoint='yoochoose1_64_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRGNN(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v1, mrr_v1,loss_v1 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v1, args.topk, mrr_v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diginetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 719470\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 60858\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           7,195      \n",
      "test mini-batch               609        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 609/609 [00:20<00:00, 30.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.5157, MRR@20: 0.1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"SRGNN\"\n",
    "\n",
    "args.dataset_path='./diginetica_data/'\n",
    "args.n_items=43098\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=128\n",
    "args.num_layers=1\n",
    "args.model_checkpoint='diginetica_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRGNN(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v2, mrr_v2,loss_v2 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v2, args.topk, mrr_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 3536\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 305\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           111        \n",
      "test mini-batch               10         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 65.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.7386, MRR@20: 0.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"SRGNN\"\n",
    "\n",
    "args.dataset_path=\"./dataset/amex_explorepoi-poi_category/\"\n",
    "args.n_items=556\n",
    "args.batch_size=32 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=256\n",
    "args.num_layers=1\n",
    "args.model_checkpoint='amex_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRGNN(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v3, mrr_v3,loss_v3 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v3, args.topk, mrr_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_42fbe_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall@20</th>\n",
       "      <th class=\"col_heading level0 col3\" >MRR@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_42fbe_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_42fbe_row0_col0\" class=\"data row0 col0\" >NARM</td>\n",
       "      <td id=\"T_42fbe_row0_col1\" class=\"data row0 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_42fbe_row0_col2\" class=\"data row0 col2\" >69.79%</td>\n",
       "      <td id=\"T_42fbe_row0_col3\" class=\"data row0 col3\" >29.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42fbe_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_42fbe_row1_col0\" class=\"data row1 col0\" >NARM</td>\n",
       "      <td id=\"T_42fbe_row1_col1\" class=\"data row1 col1\" >diginetica</td>\n",
       "      <td id=\"T_42fbe_row1_col2\" class=\"data row1 col2\" >47.43%</td>\n",
       "      <td id=\"T_42fbe_row1_col3\" class=\"data row1 col3\" >15.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42fbe_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_42fbe_row2_col0\" class=\"data row2 col0\" >NARM</td>\n",
       "      <td id=\"T_42fbe_row2_col1\" class=\"data row2 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_42fbe_row2_col2\" class=\"data row2 col2\" >68.27%</td>\n",
       "      <td id=\"T_42fbe_row2_col3\" class=\"data row2 col3\" >46.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42fbe_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_42fbe_row3_col0\" class=\"data row3 col0\" >SRGNN</td>\n",
       "      <td id=\"T_42fbe_row3_col1\" class=\"data row3 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_42fbe_row3_col2\" class=\"data row3 col2\" >70.74%</td>\n",
       "      <td id=\"T_42fbe_row3_col3\" class=\"data row3 col3\" >31.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42fbe_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_42fbe_row4_col0\" class=\"data row4 col0\" >SRGNN</td>\n",
       "      <td id=\"T_42fbe_row4_col1\" class=\"data row4 col1\" >diginetica</td>\n",
       "      <td id=\"T_42fbe_row4_col2\" class=\"data row4 col2\" >51.57%</td>\n",
       "      <td id=\"T_42fbe_row4_col3\" class=\"data row4 col3\" >17.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42fbe_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_42fbe_row5_col0\" class=\"data row5 col0\" >SRGNN</td>\n",
       "      <td id=\"T_42fbe_row5_col1\" class=\"data row5 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_42fbe_row5_col2\" class=\"data row5 col2\" >73.86%</td>\n",
       "      <td id=\"T_42fbe_row5_col3\" class=\"data row5 col3\" >41.79%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcf99d69be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempt={\"Model\":[\"SRGNN\"]*3, \"Dataset\":[\"yoochoose1_64\",\"diginetica\",\"amex-poi-category\"],\n",
    "      \"Recall@20\":[recall_v1,recall_v2,recall_v3],\"MRR@20\":[mrr_v1,mrr_v2,mrr_v3]}\n",
    "tempt=pd.DataFrame(tempt)\n",
    "output_df=output_df.append(tempt,ignore_index=True)\n",
    "output_df.style.format({'Recall@20':'{:.2%}','MRR@20':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NISER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path=list(set(sys.path))\n",
    "root_dir='/home/ec2-user/SageMaker/sequence-based-recommendation'\n",
    "old_model_name=\"SRGNN\"\n",
    "old_model_path=os.path.join(root_dir,old_model_name)\n",
    "sys.path=[x for x in sys.path if x !=old_model_path]\n",
    "\n",
    "model_name=\"NISER\"\n",
    "model_path=os.path.join(root_dir,model_name)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "from NISER.niser import NISER\n",
    "from NISER.collate import (collate_fn_factory, seq_to_session_graph)\n",
    "from NISER import metric\n",
    "from NISER.dataset import load_data,RecSysDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=100, dataset_dir='../YOOCHOOSE_data/yoochoose1_64/', embedding_dim=128, epochs=30, feat_drop=0.1, model_checkpoint='amex_checkpoint.pth', n_items=37484, num_layers=1, num_workers=0, output_name='amex_metrics.txt', seed=101, topk=20)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\n",
    "    '--dataset-dir', default='../YOOCHOOSE_data/yoochoose1_64/', help='the dataset directory'\n",
    ")\n",
    "parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "        help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "parser.add_argument('--n_items', type=int, default=37484, help='number of unique items. 37484 for yoochoose')\n",
    "parser.add_argument('--embedding-dim', type=int, default=128, help='the embedding size')\n",
    "parser.add_argument('--num-layers', type=int, default=1, help='the number of layers')\n",
    "parser.add_argument('--feat-drop', type=float, default=0.1, help='the dropout ratio for features')\n",
    "parser.add_argument('--batch-size', type=int, default=100, help='the batch size for training')\n",
    "parser.add_argument('--epochs', type=int, default=30, help='the number of training epochs')\n",
    "parser.add_argument(\"--output_name\", type=str, default=\"amex_metrics.txt\")\n",
    "parser.add_argument(\"--model_checkpoint\", type=str, default=\"amex_checkpoint.pth\")\n",
    "parser.add_argument('--topk', type=int, default=20, help='number of top score items selected for calculating recall and mrr metrics')\n",
    "parser.add_argument('--num-workers',type=int,default=0,help='the number of processes to load the input graphs')\n",
    "args,_= parser.parse_known_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yoochoose1_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 369859\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           3,699      \n",
      "test mini-batch               559        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 559/559 [00:18<00:00, 29.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.7193, MRR@20: 0.3171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"NISER\"\n",
    "\n",
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_64/'\n",
    "args.n_items=37484\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=128\n",
    "args.num_layers=1\n",
    "args.model_checkpoint='yoochoose1_64_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NISER(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v1, mrr_v1,loss_v1 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v1, args.topk, mrr_v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diginetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 719470\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 60858\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           7,195      \n",
      "test mini-batch               609        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 609/609 [00:20<00:00, 30.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.5500, MRR@20: 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"NISER\"\n",
    "\n",
    "args.dataset_path='./diginetica_data/'\n",
    "args.n_items=43098\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=128\n",
    "args.num_layers=1\n",
    "args.model_checkpoint='diginetica_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NISER(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v2, mrr_v2,loss_v2 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v2, args.topk, mrr_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 3536\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 305\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           111        \n",
      "test mini-batch               10         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 64.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.8511, MRR@20: 0.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"NISER\"\n",
    "\n",
    "args.dataset_path=\"./dataset/amex_explorepoi-poi_category/\"\n",
    "args.n_items=556\n",
    "args.batch_size=32 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=256\n",
    "args.num_layers=1\n",
    "args.model_checkpoint='amex_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NISER(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v3, mrr_v3,loss_v3 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v3, args.topk, mrr_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_03e85_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall@20</th>\n",
       "      <th class=\"col_heading level0 col3\" >MRR@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_03e85_row0_col0\" class=\"data row0 col0\" >NARM</td>\n",
       "      <td id=\"T_03e85_row0_col1\" class=\"data row0 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_03e85_row0_col2\" class=\"data row0 col2\" >69.79%</td>\n",
       "      <td id=\"T_03e85_row0_col3\" class=\"data row0 col3\" >29.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_03e85_row1_col0\" class=\"data row1 col0\" >NARM</td>\n",
       "      <td id=\"T_03e85_row1_col1\" class=\"data row1 col1\" >diginetica</td>\n",
       "      <td id=\"T_03e85_row1_col2\" class=\"data row1 col2\" >47.43%</td>\n",
       "      <td id=\"T_03e85_row1_col3\" class=\"data row1 col3\" >15.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_03e85_row2_col0\" class=\"data row2 col0\" >NARM</td>\n",
       "      <td id=\"T_03e85_row2_col1\" class=\"data row2 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_03e85_row2_col2\" class=\"data row2 col2\" >68.27%</td>\n",
       "      <td id=\"T_03e85_row2_col3\" class=\"data row2 col3\" >46.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_03e85_row3_col0\" class=\"data row3 col0\" >SRGNN</td>\n",
       "      <td id=\"T_03e85_row3_col1\" class=\"data row3 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_03e85_row3_col2\" class=\"data row3 col2\" >70.74%</td>\n",
       "      <td id=\"T_03e85_row3_col3\" class=\"data row3 col3\" >31.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_03e85_row4_col0\" class=\"data row4 col0\" >SRGNN</td>\n",
       "      <td id=\"T_03e85_row4_col1\" class=\"data row4 col1\" >diginetica</td>\n",
       "      <td id=\"T_03e85_row4_col2\" class=\"data row4 col2\" >51.57%</td>\n",
       "      <td id=\"T_03e85_row4_col3\" class=\"data row4 col3\" >17.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_03e85_row5_col0\" class=\"data row5 col0\" >SRGNN</td>\n",
       "      <td id=\"T_03e85_row5_col1\" class=\"data row5 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_03e85_row5_col2\" class=\"data row5 col2\" >73.86%</td>\n",
       "      <td id=\"T_03e85_row5_col3\" class=\"data row5 col3\" >41.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_03e85_row6_col0\" class=\"data row6 col0\" >NISER</td>\n",
       "      <td id=\"T_03e85_row6_col1\" class=\"data row6 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_03e85_row6_col2\" class=\"data row6 col2\" >71.93%</td>\n",
       "      <td id=\"T_03e85_row6_col3\" class=\"data row6 col3\" >31.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_03e85_row7_col0\" class=\"data row7 col0\" >NISER</td>\n",
       "      <td id=\"T_03e85_row7_col1\" class=\"data row7 col1\" >diginetica</td>\n",
       "      <td id=\"T_03e85_row7_col2\" class=\"data row7 col2\" >55.00%</td>\n",
       "      <td id=\"T_03e85_row7_col3\" class=\"data row7 col3\" >18.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03e85_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_03e85_row8_col0\" class=\"data row8 col0\" >NISER</td>\n",
       "      <td id=\"T_03e85_row8_col1\" class=\"data row8 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_03e85_row8_col2\" class=\"data row8 col2\" >85.11%</td>\n",
       "      <td id=\"T_03e85_row8_col3\" class=\"data row8 col3\" >59.49%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fce853519a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempt={\"Model\":[\"NISER\"]*3, \"Dataset\":[\"yoochoose1_64\",\"diginetica\",\"amex-poi-category\"],\n",
    "      \"Recall@20\":[recall_v1,recall_v2,recall_v3],\"MRR@20\":[mrr_v1,mrr_v2,mrr_v3]}\n",
    "tempt=pd.DataFrame(tempt)\n",
    "output_df=output_df.append(tempt,ignore_index=True)\n",
    "output_df.style.format({'Recall@20':'{:.2%}','MRR@20':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path=list(set(sys.path))\n",
    "root_dir='/home/ec2-user/SageMaker/sequence-based-recommendation'\n",
    "old_model_name=\"NISER\"\n",
    "old_model_path=os.path.join(root_dir,old_model_name)\n",
    "sys.path=[x for x in sys.path if x !=old_model_path]\n",
    "\n",
    "model_name=\"TAGNN\"\n",
    "model_path=os.path.join(root_dir,model_name)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "from TAGNN.utils import build_graph, Data, split_validation\n",
    "from TAGNN.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accumulation_steps=2, batchSize=100, dataset='../YOOCHOOSE_data/yoochoose1_64/', epoch=30, gradient_accumulation=False, hiddenSize=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=3, model_checkpoint='amex_checkpoint.pth', nonhybrid=False, output_name='amex_metrics.txt', patience=10, step=1, topk=20, valid_portion=0.1, validation=False)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default='../YOOCHOOSE_data/yoochoose1_64/', help='the dataset directory')\n",
    "parser.add_argument('--batchSize', type=int, default=100, help='input batch size')\n",
    "parser.add_argument('--hiddenSize', type=int, default=100, help='hidden state size')\n",
    "parser.add_argument('--epoch', type=int, default=30, help='the number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')  # [0.001, 0.0005, 0.0001]\n",
    "parser.add_argument('--lr_dc', type=float, default=0.1, help='learning rate decay rate')\n",
    "parser.add_argument('--lr_dc_step', type=int, default=3, help='the number of steps after which the learning rate decay')\n",
    "parser.add_argument('--l2', type=float, default=1e-5, help='l2 penalty')  # [0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n",
    "parser.add_argument(\"--gradient_accumulation\",action='store_true', help='gradient accumulation or not')\n",
    "parser.add_argument(\"--accumulation_steps\",type=int,default=2,\n",
    "                           help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "parser.add_argument('--step', type=int, default=1, help='gnn propogation steps')\n",
    "parser.add_argument('--patience', type=int, default=10, help='the number of epoch to wait before early stop ')\n",
    "parser.add_argument('--nonhybrid', action='store_true', help='only use the global preference to predict')\n",
    "parser.add_argument('--validation', action='store_true', help='validation')\n",
    "parser.add_argument('--valid_portion', type=float, default=0.1, help='split the portion of training set as validation set')\n",
    "parser.add_argument(\"--output_name\", type=str, default=\"amex_metrics.txt\")\n",
    "parser.add_argument(\"--model_checkpoint\", type=str, default=\"amex_checkpoint.pth\")\n",
    "parser.add_argument('--topk', type=int, default=20, help='number of top score items selected for calculating recall and mrr metrics')\n",
    "args,_= parser.parse_known_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yoochoose1_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/559 [00:00<?, ?it/s]/home/ec2-user/SageMaker/sequence-based-recommendation/TAGNN/model.py:149: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  A = trans_to_cuda(torch.Tensor(A).float())\n",
      "100%|██████████| 559/559 [00:50<00:00, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.7066, MRR@20: 0.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"TAGNN\"\n",
    "\n",
    "args.dataset='./YOOCHOOSE_data/yoochoose1_64/'\n",
    "args.batchSize=100\n",
    "args.epoch=30\n",
    "args.hiddenSize=128\n",
    "args.step=1\n",
    "args.model_checkpoint=\"yoochoose1_64_checkpoint.pth\"\n",
    "\n",
    "n_node=37484\n",
    "\n",
    "train_path_data=os.path.join(args.dataset,\"train.txt\")\n",
    "test_path_data=os.path.join(args.dataset,\"test.txt\")\n",
    "with open(train_path_data, 'rb') as f1:\n",
    "    train_data = pickle.load(f1)\n",
    "with open(test_path_data, 'rb') as f2:\n",
    "    test_data = pickle.load(f2)\n",
    "\n",
    "train_data = Data(train_data, shuffle=True)\n",
    "test_data = Data(test_data, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SessionGraph(args, n_node).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "hit, mrr = [], []\n",
    "slices = test_data.generate_batch(model.batch_size)\n",
    "for i in tqdm(slices, total=len(slices),position=0, leave=True):\n",
    "    targets, scores = forward(model, i, test_data)\n",
    "    sub_scores = scores.topk(20)[1]\n",
    "    sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
    "    for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
    "        hit.append(np.isin(target - 1, score))\n",
    "        if len(np.where(score == target - 1)[0]) == 0:\n",
    "            mrr.append(0)\n",
    "        else:\n",
    "            mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "recall_v1 = np.mean(hit)\n",
    "mrr_v1 = np.mean(mrr) \n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v1, args.topk, mrr_v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diginetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 609/609 [00:44<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.5247, MRR@20: 0.1837\n"
     ]
    }
   ],
   "source": [
    "model_name=\"TAGNN\"\n",
    "\n",
    "args.dataset='./diginetica_data/'\n",
    "args.batchSize=100\n",
    "args.epoch=30\n",
    "args.hiddenSize=128\n",
    "args.step=1\n",
    "args.model_checkpoint=\"diginetica_checkpoint.pth\"\n",
    "\n",
    "n_node=43098\n",
    "\n",
    "train_path_data=os.path.join(args.dataset,\"train.txt\")\n",
    "test_path_data=os.path.join(args.dataset,\"test.txt\")\n",
    "with open(train_path_data, 'rb') as f1:\n",
    "    train_data = pickle.load(f1)\n",
    "with open(test_path_data, 'rb') as f2:\n",
    "    test_data = pickle.load(f2)\n",
    "\n",
    "train_data = Data(train_data, shuffle=True)\n",
    "test_data = Data(test_data, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SessionGraph(args, n_node).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "hit, mrr = [], []\n",
    "slices = test_data.generate_batch(model.batch_size)\n",
    "for i in tqdm(slices, total=len(slices),position=0, leave=True):\n",
    "    targets, scores = forward(model, i, test_data)\n",
    "    sub_scores = scores.topk(20)[1]\n",
    "    sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
    "    for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
    "        hit.append(np.isin(target - 1, score))\n",
    "        if len(np.where(score == target - 1)[0]) == 0:\n",
    "            mrr.append(0)\n",
    "        else:\n",
    "            mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "recall_v2 = np.mean(hit)\n",
    "mrr_v2 = np.mean(mrr)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v2, args.topk, mrr_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 100.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.7311, MRR@20: 0.4154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"TAGNN\"\n",
    "\n",
    "args.dataset='./dataset/amex_explorepoi-poi_category/'\n",
    "args.batchSize=32\n",
    "args.epoch=30\n",
    "args.hiddenSize=256\n",
    "args.step=1\n",
    "args.model_checkpoint=\"amex_checkpoint.pth\"\n",
    "\n",
    "n_node=556\n",
    "\n",
    "train_path_data=os.path.join(args.dataset,\"train.txt\")\n",
    "test_path_data=os.path.join(args.dataset,\"test.txt\")\n",
    "with open(train_path_data, 'rb') as f1:\n",
    "    train_data = pickle.load(f1)\n",
    "with open(test_path_data, 'rb') as f2:\n",
    "    test_data = pickle.load(f2)\n",
    "\n",
    "train_data = Data(train_data, shuffle=True)\n",
    "test_data = Data(test_data, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SessionGraph(args, n_node).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "hit, mrr = [], []\n",
    "slices = test_data.generate_batch(model.batch_size)\n",
    "for i in tqdm(slices, total=len(slices),position=0, leave=True):\n",
    "    targets, scores = forward(model, i, test_data)\n",
    "    sub_scores = scores.topk(20)[1]\n",
    "    sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
    "    for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
    "        hit.append(np.isin(target - 1, score))\n",
    "        if len(np.where(score == target - 1)[0]) == 0:\n",
    "            mrr.append(0)\n",
    "        else:\n",
    "            mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "recall_v3 = np.mean(hit)\n",
    "mrr_v3 = np.mean(mrr)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v3, args.topk, mrr_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cddf6_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall@20</th>\n",
       "      <th class=\"col_heading level0 col3\" >MRR@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cddf6_row0_col0\" class=\"data row0 col0\" >NARM</td>\n",
       "      <td id=\"T_cddf6_row0_col1\" class=\"data row0 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_cddf6_row0_col2\" class=\"data row0 col2\" >69.79%</td>\n",
       "      <td id=\"T_cddf6_row0_col3\" class=\"data row0 col3\" >29.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cddf6_row1_col0\" class=\"data row1 col0\" >NARM</td>\n",
       "      <td id=\"T_cddf6_row1_col1\" class=\"data row1 col1\" >diginetica</td>\n",
       "      <td id=\"T_cddf6_row1_col2\" class=\"data row1 col2\" >47.43%</td>\n",
       "      <td id=\"T_cddf6_row1_col3\" class=\"data row1 col3\" >15.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cddf6_row2_col0\" class=\"data row2 col0\" >NARM</td>\n",
       "      <td id=\"T_cddf6_row2_col1\" class=\"data row2 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_cddf6_row2_col2\" class=\"data row2 col2\" >68.27%</td>\n",
       "      <td id=\"T_cddf6_row2_col3\" class=\"data row2 col3\" >46.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cddf6_row3_col0\" class=\"data row3 col0\" >SRGNN</td>\n",
       "      <td id=\"T_cddf6_row3_col1\" class=\"data row3 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_cddf6_row3_col2\" class=\"data row3 col2\" >70.74%</td>\n",
       "      <td id=\"T_cddf6_row3_col3\" class=\"data row3 col3\" >31.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_cddf6_row4_col0\" class=\"data row4 col0\" >SRGNN</td>\n",
       "      <td id=\"T_cddf6_row4_col1\" class=\"data row4 col1\" >diginetica</td>\n",
       "      <td id=\"T_cddf6_row4_col2\" class=\"data row4 col2\" >51.57%</td>\n",
       "      <td id=\"T_cddf6_row4_col3\" class=\"data row4 col3\" >17.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_cddf6_row5_col0\" class=\"data row5 col0\" >SRGNN</td>\n",
       "      <td id=\"T_cddf6_row5_col1\" class=\"data row5 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_cddf6_row5_col2\" class=\"data row5 col2\" >73.86%</td>\n",
       "      <td id=\"T_cddf6_row5_col3\" class=\"data row5 col3\" >41.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_cddf6_row6_col0\" class=\"data row6 col0\" >NISER</td>\n",
       "      <td id=\"T_cddf6_row6_col1\" class=\"data row6 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_cddf6_row6_col2\" class=\"data row6 col2\" >71.93%</td>\n",
       "      <td id=\"T_cddf6_row6_col3\" class=\"data row6 col3\" >31.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_cddf6_row7_col0\" class=\"data row7 col0\" >NISER</td>\n",
       "      <td id=\"T_cddf6_row7_col1\" class=\"data row7 col1\" >diginetica</td>\n",
       "      <td id=\"T_cddf6_row7_col2\" class=\"data row7 col2\" >55.00%</td>\n",
       "      <td id=\"T_cddf6_row7_col3\" class=\"data row7 col3\" >18.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_cddf6_row8_col0\" class=\"data row8 col0\" >NISER</td>\n",
       "      <td id=\"T_cddf6_row8_col1\" class=\"data row8 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_cddf6_row8_col2\" class=\"data row8 col2\" >85.11%</td>\n",
       "      <td id=\"T_cddf6_row8_col3\" class=\"data row8 col3\" >59.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_cddf6_row9_col0\" class=\"data row9 col0\" >TAGNN</td>\n",
       "      <td id=\"T_cddf6_row9_col1\" class=\"data row9 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_cddf6_row9_col2\" class=\"data row9 col2\" >70.66%</td>\n",
       "      <td id=\"T_cddf6_row9_col3\" class=\"data row9 col3\" >30.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_cddf6_row10_col0\" class=\"data row10 col0\" >TAGNN</td>\n",
       "      <td id=\"T_cddf6_row10_col1\" class=\"data row10 col1\" >diginetica</td>\n",
       "      <td id=\"T_cddf6_row10_col2\" class=\"data row10 col2\" >52.47%</td>\n",
       "      <td id=\"T_cddf6_row10_col3\" class=\"data row10 col3\" >18.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cddf6_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_cddf6_row11_col0\" class=\"data row11 col0\" >TAGNN</td>\n",
       "      <td id=\"T_cddf6_row11_col1\" class=\"data row11 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_cddf6_row11_col2\" class=\"data row11 col2\" >73.11%</td>\n",
       "      <td id=\"T_cddf6_row11_col3\" class=\"data row11 col3\" >41.54%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcec1f403d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempt={\"Model\":[\"TAGNN\"]*3, \"Dataset\":[\"yoochoose1_64\",\"diginetica\",\"amex-poi-category\"],\n",
    "      \"Recall@20\":[recall_v1,recall_v2,recall_v3],\"MRR@20\":[mrr_v1,mrr_v2,mrr_v3]}\n",
    "tempt=pd.DataFrame(tempt)\n",
    "output_df=output_df.append(tempt,ignore_index=True)\n",
    "output_df.style.format({'Recall@20':'{:.2%}','MRR@20':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LESSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path=list(set(sys.path))\n",
    "root_dir='/home/ec2-user/SageMaker/sequence-based-recommendation'\n",
    "old_model_name=\"TAGNN\"\n",
    "old_model_path=os.path.join(root_dir,old_model_name)\n",
    "sys.path=[x for x in sys.path if x !=old_model_path]\n",
    "\n",
    "model_name=\"LESSR\"\n",
    "model_path=os.path.join(root_dir,model_name)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "from LESSR.lessr import LESSR\n",
    "from LESSR.collate import (collate_fn_factory, seq_to_eop_multigraph,seq_to_shortcut_graph)\n",
    "from LESSR import metric\n",
    "from LESSR.dataset import load_data,RecSysDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=100, dataset_dir='../YOOCHOOSE_data/yoochoose1_64/', embedding_dim=128, epochs=30, feat_drop=0.1, model_checkpoint='amex_checkpoint.pth', n_items=37484, num_layers=1, num_workers=0, step=1, topk=20)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\n",
    "    '--dataset-dir', default='../YOOCHOOSE_data/yoochoose1_64/', help='the dataset directory'\n",
    ")\n",
    "parser.add_argument('--n_items', type=int, default=37484, help='number of unique items. 37484 for yoochoose')\n",
    "parser.add_argument('--embedding-dim', type=int, default=128, help='the embedding size')\n",
    "parser.add_argument('--num-layers', type=int, default=1, help='the number of layers')\n",
    "parser.add_argument('--feat-drop', type=float, default=0.1, help='the dropout ratio for features')\n",
    "parser.add_argument('--step', type=int, default=1, help='gnn propogation steps')\n",
    "parser.add_argument('--batch-size', type=int, default=100, help='the batch size for training')\n",
    "parser.add_argument('--epochs', type=int, default=30, help='the number of training epochs')\n",
    "parser.add_argument(\"--model_checkpoint\", type=str, default=\"amex_checkpoint.pth\") \n",
    "parser.add_argument('--topk', type=int, default=20, help='number of top score items selected for calculating recall and mrr metrics')\n",
    "parser.add_argument('--num-workers',type=int,default=0,help='the number of processes to load the input graphs') \n",
    "args,_= parser.parse_known_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yoochoose1_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 369859\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           3,699      \n",
      "test mini-batch               559        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 559/559 [00:27<00:00, 20.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.6888, MRR@20: 0.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"LESSR\"\n",
    "\n",
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_64/'\n",
    "args.n_items=37484\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=256\n",
    "args.num_layers=3\n",
    "args.model_checkpoint='yoochoose1_64_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "if args.num_layers > 1:\n",
    "    collate_fn = collate_fn_factory(seq_to_eop_multigraph, seq_to_shortcut_graph)\n",
    "else:\n",
    "    collate_fn = collate_fn_factory(seq_to_eop_multigraph)\n",
    "        \n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LESSR(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v1, mrr_v1,loss_v1 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v1, args.topk, mrr_v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir=os.path.join(os.getcwd(), \"LESSR\",\"output_metrics\")\n",
    "# file_name=\"test_yoochoose1_64_metrics.txt\"\n",
    "# output=[]\n",
    "# with open(os.path.join(root_dir,file_name),'r') as f:\n",
    "#     for line in f:\n",
    "#         output.append((line.split(\",\")[1].strip(\"\\n\"),line.split(\",\")[2].strip(\"\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diginetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name=\"LESSR\"\n",
    "\n",
    "# args.dataset_path='./diginetica_data/'\n",
    "# args.n_items=43098\n",
    "# args.batch_size=100 \n",
    "# args.epoch=30 \n",
    "# args.embedding_dim=256\n",
    "# args.num_layers=3\n",
    "# args.model_checkpoint='diginetica_checkpoint.pth'\n",
    "\n",
    "# train, test = load_data(args.dataset_path)\n",
    "# train_data = RecSysDataset(train)\n",
    "# test_data = RecSysDataset(test)\n",
    "\n",
    "# collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "# train_loader = DataLoader(\n",
    "#     train_data,\n",
    "#     batch_size=args.batch_size,\n",
    "#     # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "#     # drop_last=True,\n",
    "#     num_workers=args.num_workers,\n",
    "#     collate_fn=collate_fn,\n",
    "#     pin_memory=True,\n",
    "#     sampler=SequentialSampler(train_data)\n",
    "# )\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#     test_data,\n",
    "#     batch_size=args.batch_size,\n",
    "#     # shuffle=True,\n",
    "#     num_workers=args.num_workers,\n",
    "#     collate_fn=collate_fn\n",
    "# )\n",
    "# print()\n",
    "# print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "# print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = LESSR(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "# model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "# ckpt = torch.load(model_path)\n",
    "# model.load_state_dict(ckpt['state_dict'])\n",
    "# recall_v2, mrr_v2,loss_v2 = validate(test_loader, model,device)\n",
    "# print()\n",
    "# print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v2, args.topk, mrr_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=os.path.join(os.getcwd(), \"LESSR\",\"output_metrics\")\n",
    "file_name=\"test_diginetica_metrics.txt\"\n",
    "output=[]\n",
    "with open(os.path.join(root_dir,file_name),'r') as f:\n",
    "    for line in f:\n",
    "        output.append((line.split(\",\")[1].strip(\"\\n\"),line.split(\",\")[2].strip(\"\\n\")))\n",
    "        \n",
    "import operator\n",
    "output=sorted(output, key=operator.itemgetter(1),reverse=True)\n",
    "recall_v2=output[0][0]\n",
    "mrr_v2=output[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name=\"LESSR\"\n",
    "\n",
    "# args.dataset_path=\"./dataset/amex_explorepoi-poi_category/\"\n",
    "# args.n_items=556\n",
    "# args.batch_size=32 \n",
    "# args.epoch=30 \n",
    "# args.embedding_dim=256\n",
    "# args.num_layers=3\n",
    "# args.model_checkpoint='amex_checkpoint.pth'\n",
    "\n",
    "# train, test = load_data(args.dataset_path)\n",
    "# train_data = RecSysDataset(train)\n",
    "# test_data = RecSysDataset(test)\n",
    "\n",
    "# collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "# train_loader = DataLoader(\n",
    "#     train_data,\n",
    "#     batch_size=args.batch_size,\n",
    "#     # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "#     # drop_last=True,\n",
    "#     num_workers=args.num_workers,\n",
    "#     collate_fn=collate_fn,\n",
    "#     pin_memory=True,\n",
    "#     sampler=SequentialSampler(train_data)\n",
    "# )\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#     test_data,\n",
    "#     batch_size=args.batch_size,\n",
    "#     # shuffle=True,\n",
    "#     num_workers=args.num_workers,\n",
    "#     collate_fn=collate_fn\n",
    "# )\n",
    "# print()\n",
    "# print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "# print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = LESSR(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "\n",
    "# model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "# ckpt = torch.load(model_path)\n",
    "# model.load_state_dict(ckpt['state_dict'])\n",
    "# recall_v3, mrr_v3,loss_v3 = validate(test_loader, model,device)\n",
    "# print()\n",
    "# print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v3, args.topk, mrr_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=os.path.join(os.getcwd(), \"LESSR\",\"output_metrics\")\n",
    "file_name=\"test_amex_metrics.txt\"\n",
    "output=[]\n",
    "with open(os.path.join(root_dir,file_name),'r') as f:\n",
    "    for line in f:\n",
    "        output.append((line.split(\",\")[1].strip(\"\\n\"),line.split(\",\")[2].strip(\"\\n\")))\n",
    "\n",
    "import operator\n",
    "output=sorted(output, key=operator.itemgetter(1),reverse=True)\n",
    "recall_v3=output[0][0]\n",
    "mrr_v3=output[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_84b18_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall@20</th>\n",
       "      <th class=\"col_heading level0 col3\" >MRR@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_84b18_row0_col0\" class=\"data row0 col0\" >NARM</td>\n",
       "      <td id=\"T_84b18_row0_col1\" class=\"data row0 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_84b18_row0_col2\" class=\"data row0 col2\" >69.79%</td>\n",
       "      <td id=\"T_84b18_row0_col3\" class=\"data row0 col3\" >29.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_84b18_row1_col0\" class=\"data row1 col0\" >NARM</td>\n",
       "      <td id=\"T_84b18_row1_col1\" class=\"data row1 col1\" >diginetica</td>\n",
       "      <td id=\"T_84b18_row1_col2\" class=\"data row1 col2\" >47.43%</td>\n",
       "      <td id=\"T_84b18_row1_col3\" class=\"data row1 col3\" >15.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_84b18_row2_col0\" class=\"data row2 col0\" >NARM</td>\n",
       "      <td id=\"T_84b18_row2_col1\" class=\"data row2 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_84b18_row2_col2\" class=\"data row2 col2\" >68.27%</td>\n",
       "      <td id=\"T_84b18_row2_col3\" class=\"data row2 col3\" >46.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_84b18_row3_col0\" class=\"data row3 col0\" >SRGNN</td>\n",
       "      <td id=\"T_84b18_row3_col1\" class=\"data row3 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_84b18_row3_col2\" class=\"data row3 col2\" >70.74%</td>\n",
       "      <td id=\"T_84b18_row3_col3\" class=\"data row3 col3\" >31.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_84b18_row4_col0\" class=\"data row4 col0\" >SRGNN</td>\n",
       "      <td id=\"T_84b18_row4_col1\" class=\"data row4 col1\" >diginetica</td>\n",
       "      <td id=\"T_84b18_row4_col2\" class=\"data row4 col2\" >51.57%</td>\n",
       "      <td id=\"T_84b18_row4_col3\" class=\"data row4 col3\" >17.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_84b18_row5_col0\" class=\"data row5 col0\" >SRGNN</td>\n",
       "      <td id=\"T_84b18_row5_col1\" class=\"data row5 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_84b18_row5_col2\" class=\"data row5 col2\" >73.86%</td>\n",
       "      <td id=\"T_84b18_row5_col3\" class=\"data row5 col3\" >41.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_84b18_row6_col0\" class=\"data row6 col0\" >NISER</td>\n",
       "      <td id=\"T_84b18_row6_col1\" class=\"data row6 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_84b18_row6_col2\" class=\"data row6 col2\" >71.93%</td>\n",
       "      <td id=\"T_84b18_row6_col3\" class=\"data row6 col3\" >31.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_84b18_row7_col0\" class=\"data row7 col0\" >NISER</td>\n",
       "      <td id=\"T_84b18_row7_col1\" class=\"data row7 col1\" >diginetica</td>\n",
       "      <td id=\"T_84b18_row7_col2\" class=\"data row7 col2\" >55.00%</td>\n",
       "      <td id=\"T_84b18_row7_col3\" class=\"data row7 col3\" >18.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_84b18_row8_col0\" class=\"data row8 col0\" >NISER</td>\n",
       "      <td id=\"T_84b18_row8_col1\" class=\"data row8 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_84b18_row8_col2\" class=\"data row8 col2\" >85.11%</td>\n",
       "      <td id=\"T_84b18_row8_col3\" class=\"data row8 col3\" >59.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_84b18_row9_col0\" class=\"data row9 col0\" >TAGNN</td>\n",
       "      <td id=\"T_84b18_row9_col1\" class=\"data row9 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_84b18_row9_col2\" class=\"data row9 col2\" >70.66%</td>\n",
       "      <td id=\"T_84b18_row9_col3\" class=\"data row9 col3\" >30.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_84b18_row10_col0\" class=\"data row10 col0\" >TAGNN</td>\n",
       "      <td id=\"T_84b18_row10_col1\" class=\"data row10 col1\" >diginetica</td>\n",
       "      <td id=\"T_84b18_row10_col2\" class=\"data row10 col2\" >52.47%</td>\n",
       "      <td id=\"T_84b18_row10_col3\" class=\"data row10 col3\" >18.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_84b18_row11_col0\" class=\"data row11 col0\" >TAGNN</td>\n",
       "      <td id=\"T_84b18_row11_col1\" class=\"data row11 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_84b18_row11_col2\" class=\"data row11 col2\" >73.11%</td>\n",
       "      <td id=\"T_84b18_row11_col3\" class=\"data row11 col3\" >41.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_84b18_row12_col0\" class=\"data row12 col0\" >LESSR</td>\n",
       "      <td id=\"T_84b18_row12_col1\" class=\"data row12 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_84b18_row12_col2\" class=\"data row12 col2\" >68.88%</td>\n",
       "      <td id=\"T_84b18_row12_col3\" class=\"data row12 col3\" >29.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_84b18_row13_col0\" class=\"data row13 col0\" >LESSR</td>\n",
       "      <td id=\"T_84b18_row13_col1\" class=\"data row13 col1\" >diginetica</td>\n",
       "      <td id=\"T_84b18_row13_col2\" class=\"data row13 col2\" >49.66%</td>\n",
       "      <td id=\"T_84b18_row13_col3\" class=\"data row13 col3\" >15.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84b18_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_84b18_row14_col0\" class=\"data row14 col0\" >LESSR</td>\n",
       "      <td id=\"T_84b18_row14_col1\" class=\"data row14 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_84b18_row14_col2\" class=\"data row14 col2\" >69.56%</td>\n",
       "      <td id=\"T_84b18_row14_col3\" class=\"data row14 col3\" >56.86%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcf9e6d32e0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempt={\"Model\":[\"LESSR\"]*3, \"Dataset\":[\"yoochoose1_64\",\"diginetica\",\"amex-poi-category\"],\n",
    "      \"Recall@20\":[recall_v1,recall_v2,recall_v3],\"MRR@20\":[mrr_v1,mrr_v2,mrr_v3]}\n",
    "tempt=pd.DataFrame(tempt)\n",
    "tempt['Recall@20']=tempt['Recall@20'].astype(float)\n",
    "tempt['MRR@20']=tempt['MRR@20'].astype(float)\n",
    "output_df=output_df.append(tempt,ignore_index=True)\n",
    "output_df.style.format({'Recall@20':'{:.2%}','MRR@20':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSGIFSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path=list(set(sys.path))\n",
    "root_dir='/home/ec2-user/SageMaker/sequence-based-recommendation'\n",
    "old_model_name=\"\"\n",
    "old_model_path=os.path.join(root_dir,old_model_name)\n",
    "sys.path=[x for x in sys.path if x !=old_model_path]\n",
    "\n",
    "model_name=\"MSGIFSR\"\n",
    "model_path=os.path.join(root_dir,model_name)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "from MSGIFSR.msgifsr import MSGIFSR\n",
    "from MSGIFSR.collate import (collate_fn_factory_ccs, seq_to_ccs_graph)\n",
    "from MSGIFSR import metric\n",
    "from MSGIFSR.dataset import load_data,RecSysDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=100, dataset_dir='../YOOCHOOSE_data/yoochoose1_64/', embedding_dim=128, epochs=30, extra=False, feat_drop=0.1, fusion=False, model_checkpoint='amex_checkpoint.pth', n_items=37484, norm=True, num_layers=1, num_workers=0, order=3, reducer='mean', step=1, topk=20)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\n",
    "    '--dataset-dir', default='../YOOCHOOSE_data/yoochoose1_64/', help='the dataset directory'\n",
    ")\n",
    "parser.add_argument('--n_items', type=int, default=37484, help='number of unique items. 37484 for yoochoose')\n",
    "parser.add_argument('--embedding-dim', type=int, default=128, help='the embedding size')\n",
    "parser.add_argument('--num-layers', type=int, default=1, help='the number of layers')\n",
    "parser.add_argument('--feat-drop', type=float, default=0.1, help='the dropout ratio for features')\n",
    "parser.add_argument('--step', type=int, default=1, help='gnn propogation steps')\n",
    "parser.add_argument('--batch-size', type=int, default=100, help='the batch size for training')\n",
    "parser.add_argument('--epochs', type=int, default=30, help='the number of training epochs')\n",
    "parser.add_argument(\"--model_checkpoint\", type=str, default=\"amex_checkpoint.pth\") \n",
    "parser.add_argument('--topk', type=int, default=20, help='number of top score items selected for calculating recall and mrr metrics')\n",
    "parser.add_argument('--num-workers',type=int,default=0,help='the number of processes to load the input graphs')\n",
    "\n",
    "parser.add_argument('--order',type=int,default=3,help='order of msg')\n",
    "parser.add_argument('--reducer',type=str,default='mean',help='method for reducer')\n",
    "parser.add_argument('--norm',type=bool,default=True,help='whether use l2 norm')\n",
    "parser.add_argument('--extra',action='store_true',help='whether use REnorm.')\n",
    "parser.add_argument('--fusion',action='store_true',help='whether use IFR.')\n",
    "    \n",
    "args,_= parser.parse_known_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### yoochoose1_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 369859\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           3,699      \n",
      "test mini-batch               559        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 559/559 [02:25<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.7225, MRR@20: 0.3218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"MSGIFSR\"\n",
    "\n",
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_64/'\n",
    "args.n_items=37484\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=128\n",
    "args.num_layers=1\n",
    "args.order=3\n",
    "args.model_checkpoint='yoochoose1_64_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory_ccs((seq_to_ccs_graph,), order=args.order)\n",
    "        \n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MSGIFSR(args.n_items, args.embedding_dim, args.num_layers, dropout=args.feat_drop, reducer=args.reducer, order=args.order, \n",
    "                norm=args.norm, extra=args.extra, fusion=args.fusion, device=device)\n",
    "model=model.to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v1, mrr_v1,loss_v1 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v1, args.topk, mrr_v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diginetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 719470\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 60858\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           7,195      \n",
      "test mini-batch               609        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 609/609 [02:35<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.5564, MRR@20: 0.1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"MSGIFSR\"\n",
    "\n",
    "args.dataset_path='./diginetica_data/'\n",
    "args.n_items=43098\n",
    "args.batch_size=100 \n",
    "args.epoch=30 \n",
    "args.embedding_dim=128\n",
    "args.num_layers=1\n",
    "args.order=3\n",
    "args.model_checkpoint='diginetica_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory_ccs((seq_to_ccs_graph,), order=args.order)\n",
    "        \n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MSGIFSR(args.n_items, args.embedding_dim, args.num_layers, dropout=args.feat_drop, reducer=args.reducer, order=args.order, \n",
    "                norm=args.norm, extra=args.extra, fusion=args.fusion, device=device)\n",
    "model=model.to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v2, mrr_v2,loss_v2 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v2, args.topk, mrr_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 3536\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 305\n",
      "--------------------------------------------------\n",
      "\n",
      "training mini-batch           111        \n",
      "test mini-batch               10         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Recall@20: 0.8664, MRR@20: 0.5979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"MSGIFSR\"\n",
    "\n",
    "args.dataset_path='./dataset/amex_explorepoi-poi_category/'\n",
    "args.n_items=556\n",
    "args.batch_size=32\n",
    "args.epoch=30 \n",
    "args.embedding_dim=256\n",
    "args.num_layers=1\n",
    "args.order=3\n",
    "args.model_checkpoint='amex_checkpoint.pth'\n",
    "\n",
    "train, test = load_data(args.dataset_path)\n",
    "train_data = RecSysDataset(train)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory_ccs((seq_to_ccs_graph,), order=args.order)\n",
    "        \n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,  # Remove shuffle=True in this case as SubsetRandomSampler shuffles data already\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "print()\n",
    "print('{:<30}{:<10,} '.format(\"training mini-batch\",len(train_loader)))\n",
    "print('{:<30}{:<10,} '.format(\"test mini-batch\",len(test_loader)))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MSGIFSR(args.n_items, args.embedding_dim, args.num_layers, dropout=args.feat_drop, reducer=args.reducer, order=args.order, \n",
    "                norm=args.norm, extra=args.extra, fusion=args.fusion, device=device)\n",
    "model=model.to(device)\n",
    "\n",
    "model_path=os.path.join(os.getcwd(),model_name, args.model_checkpoint)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v3, mrr_v3,loss_v3 = validate(test_loader, model,device)\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v3, args.topk, mrr_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ffd86_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall@20</th>\n",
       "      <th class=\"col_heading level0 col3\" >MRR@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ffd86_row0_col0\" class=\"data row0 col0\" >NARM</td>\n",
       "      <td id=\"T_ffd86_row0_col1\" class=\"data row0 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_ffd86_row0_col2\" class=\"data row0 col2\" >69.79%</td>\n",
       "      <td id=\"T_ffd86_row0_col3\" class=\"data row0 col3\" >29.58%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ffd86_row1_col0\" class=\"data row1 col0\" >NARM</td>\n",
       "      <td id=\"T_ffd86_row1_col1\" class=\"data row1 col1\" >diginetica</td>\n",
       "      <td id=\"T_ffd86_row1_col2\" class=\"data row1 col2\" >47.43%</td>\n",
       "      <td id=\"T_ffd86_row1_col3\" class=\"data row1 col3\" >15.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ffd86_row2_col0\" class=\"data row2 col0\" >NARM</td>\n",
       "      <td id=\"T_ffd86_row2_col1\" class=\"data row2 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_ffd86_row2_col2\" class=\"data row2 col2\" >68.27%</td>\n",
       "      <td id=\"T_ffd86_row2_col3\" class=\"data row2 col3\" >46.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ffd86_row3_col0\" class=\"data row3 col0\" >SRGNN</td>\n",
       "      <td id=\"T_ffd86_row3_col1\" class=\"data row3 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_ffd86_row3_col2\" class=\"data row3 col2\" >70.74%</td>\n",
       "      <td id=\"T_ffd86_row3_col3\" class=\"data row3 col3\" >31.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ffd86_row4_col0\" class=\"data row4 col0\" >SRGNN</td>\n",
       "      <td id=\"T_ffd86_row4_col1\" class=\"data row4 col1\" >diginetica</td>\n",
       "      <td id=\"T_ffd86_row4_col2\" class=\"data row4 col2\" >51.57%</td>\n",
       "      <td id=\"T_ffd86_row4_col3\" class=\"data row4 col3\" >17.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ffd86_row5_col0\" class=\"data row5 col0\" >SRGNN</td>\n",
       "      <td id=\"T_ffd86_row5_col1\" class=\"data row5 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_ffd86_row5_col2\" class=\"data row5 col2\" >73.86%</td>\n",
       "      <td id=\"T_ffd86_row5_col3\" class=\"data row5 col3\" >41.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ffd86_row6_col0\" class=\"data row6 col0\" >NISER</td>\n",
       "      <td id=\"T_ffd86_row6_col1\" class=\"data row6 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_ffd86_row6_col2\" class=\"data row6 col2\" >71.93%</td>\n",
       "      <td id=\"T_ffd86_row6_col3\" class=\"data row6 col3\" >31.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ffd86_row7_col0\" class=\"data row7 col0\" >NISER</td>\n",
       "      <td id=\"T_ffd86_row7_col1\" class=\"data row7 col1\" >diginetica</td>\n",
       "      <td id=\"T_ffd86_row7_col2\" class=\"data row7 col2\" >55.00%</td>\n",
       "      <td id=\"T_ffd86_row7_col3\" class=\"data row7 col3\" >18.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ffd86_row8_col0\" class=\"data row8 col0\" >NISER</td>\n",
       "      <td id=\"T_ffd86_row8_col1\" class=\"data row8 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_ffd86_row8_col2\" class=\"data row8 col2\" >85.11%</td>\n",
       "      <td id=\"T_ffd86_row8_col3\" class=\"data row8 col3\" >59.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ffd86_row9_col0\" class=\"data row9 col0\" >TAGNN</td>\n",
       "      <td id=\"T_ffd86_row9_col1\" class=\"data row9 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_ffd86_row9_col2\" class=\"data row9 col2\" >70.66%</td>\n",
       "      <td id=\"T_ffd86_row9_col3\" class=\"data row9 col3\" >30.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ffd86_row10_col0\" class=\"data row10 col0\" >TAGNN</td>\n",
       "      <td id=\"T_ffd86_row10_col1\" class=\"data row10 col1\" >diginetica</td>\n",
       "      <td id=\"T_ffd86_row10_col2\" class=\"data row10 col2\" >52.47%</td>\n",
       "      <td id=\"T_ffd86_row10_col3\" class=\"data row10 col3\" >18.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ffd86_row11_col0\" class=\"data row11 col0\" >TAGNN</td>\n",
       "      <td id=\"T_ffd86_row11_col1\" class=\"data row11 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_ffd86_row11_col2\" class=\"data row11 col2\" >73.11%</td>\n",
       "      <td id=\"T_ffd86_row11_col3\" class=\"data row11 col3\" >41.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ffd86_row12_col0\" class=\"data row12 col0\" >LESSR</td>\n",
       "      <td id=\"T_ffd86_row12_col1\" class=\"data row12 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_ffd86_row12_col2\" class=\"data row12 col2\" >68.88%</td>\n",
       "      <td id=\"T_ffd86_row12_col3\" class=\"data row12 col3\" >29.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ffd86_row13_col0\" class=\"data row13 col0\" >LESSR</td>\n",
       "      <td id=\"T_ffd86_row13_col1\" class=\"data row13 col1\" >diginetica</td>\n",
       "      <td id=\"T_ffd86_row13_col2\" class=\"data row13 col2\" >49.66%</td>\n",
       "      <td id=\"T_ffd86_row13_col3\" class=\"data row13 col3\" >15.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ffd86_row14_col0\" class=\"data row14 col0\" >LESSR</td>\n",
       "      <td id=\"T_ffd86_row14_col1\" class=\"data row14 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_ffd86_row14_col2\" class=\"data row14 col2\" >69.56%</td>\n",
       "      <td id=\"T_ffd86_row14_col3\" class=\"data row14 col3\" >56.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ffd86_row15_col0\" class=\"data row15 col0\" >MSGIFSR</td>\n",
       "      <td id=\"T_ffd86_row15_col1\" class=\"data row15 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_ffd86_row15_col2\" class=\"data row15 col2\" >72.25%</td>\n",
       "      <td id=\"T_ffd86_row15_col3\" class=\"data row15 col3\" >32.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ffd86_row16_col0\" class=\"data row16 col0\" >MSGIFSR</td>\n",
       "      <td id=\"T_ffd86_row16_col1\" class=\"data row16 col1\" >diginetica</td>\n",
       "      <td id=\"T_ffd86_row16_col2\" class=\"data row16 col2\" >55.64%</td>\n",
       "      <td id=\"T_ffd86_row16_col3\" class=\"data row16 col3\" >19.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd86_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ffd86_row17_col0\" class=\"data row17 col0\" >MSGIFSR</td>\n",
       "      <td id=\"T_ffd86_row17_col1\" class=\"data row17 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_ffd86_row17_col2\" class=\"data row17 col2\" >86.64%</td>\n",
       "      <td id=\"T_ffd86_row17_col3\" class=\"data row17 col3\" >59.79%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fceb67600a0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempt={\"Model\":[\"MSGIFSR\"]*3, \"Dataset\":[\"yoochoose1_64\",\"diginetica\",\"amex-poi-category\"],\n",
    "      \"Recall@20\":[recall_v1,recall_v2,recall_v3],\"MRR@20\":[mrr_v1,mrr_v2,mrr_v3]}\n",
    "tempt=pd.DataFrame(tempt)\n",
    "tempt['Recall@20']=tempt['Recall@20'].astype(float)\n",
    "tempt['MRR@20']=tempt['MRR@20'].astype(float)\n",
    "output_df=output_df.append(tempt,ignore_index=True)\n",
    "output_df.style.format({'Recall@20':'{:.2%}','MRR@20':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df=output_df.loc[output_df.Model!=\"MSGIFSR\"]\n",
    "# output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"result_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bar_plot(data, colors=None, total_width=0.8, single_width=1, legend=True,title=None,subtitle=None,axis_truncation=0.5):\n",
    "#     \"\"\"Draws a bar plot with multiple bars per data point.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     ax : matplotlib.pyplot.axis\n",
    "#         The axis we want to draw our plot on.\n",
    "\n",
    "#     data: dictionary\n",
    "#         A dictionary containing the data we want to plot. Keys are the names of the\n",
    "#         data, the items is a list of the values.\n",
    "\n",
    "#         Example:\n",
    "#         data = {\n",
    "#             \"x\":[1,2,3],\n",
    "#             \"y\":[1,2,3],\n",
    "#             \"z\":[1,2,3],\n",
    "#         }\n",
    "\n",
    "#     colors : array-like, optional\n",
    "#         A list of colors which are used for the bars. If None, the colors\n",
    "#         will be the standard matplotlib color cyle. (default: None)\n",
    "\n",
    "#     total_width : float, optional, default: 0.8\n",
    "#         The width of a bar group. 0.8 means that 80% of the x-axis is covered\n",
    "#         by bars and 20% will be spaces between the bars.\n",
    "\n",
    "#     single_width: float, optional, default: 1\n",
    "#         The relative width of a single bar within a group. 1 means the bars\n",
    "#         will touch eachother within a group, values less than 1 will make\n",
    "#         these bars thinner.\n",
    "\n",
    "#     legend: bool, optional, default: True\n",
    "#         If this is set to true, a legend will be added to the axis.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Check if colors where provided, otherwhise use the default color cycle\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize =(15, 8))\n",
    "    \n",
    "#     if colors is None:\n",
    "#         colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "#     # Number of bars per group\n",
    "#     n_bars = len(data)\n",
    "\n",
    "#     # The width of a single bar\n",
    "#     bar_width = total_width / n_bars\n",
    "\n",
    "#     # List containing handles for the drawn bars, used for the legend\n",
    "#     bars = []\n",
    "\n",
    "#     # Iterate over all data\n",
    "#     for i, (name, values) in enumerate(data.items()):\n",
    "#         # The offset in x direction of that bar\n",
    "#         x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
    "\n",
    "#         # Draw a bar for every value of that type\n",
    "#         for x, y in enumerate(values):\n",
    "#             bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)])\n",
    "\n",
    "#         # Add a handle to the last drawn bar, which we'll need for the legend\n",
    "#         bars.append(bar[0])\n",
    "\n",
    "#     # Draw legend if we need\n",
    "#     if legend:\n",
    "#         ax.legend(bars, data.keys())\n",
    "    \n",
    "#     ax.set_ylabel('Accuracy Rate')\n",
    "#     ind=np.arange(len(data[list(data.keys())[0]]))\n",
    "#     ax.set_xticks(ind)\n",
    "#     ax.set_xticklabels( ('top 5% score', 'top 10% score', 'top 15% score','top 20% score') )\n",
    "#     ax.set_title(f\"Top Predicted Score \\n {subtitle} {title} \",fontsize=15)\n",
    "    \n",
    "#     #     plt.xlim([0, 1])\n",
    "#     plt.ylim([axis_truncation, 1])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     data = {\n",
    "# #         \"pretrained_longformer\": response_cust_gs,\n",
    "#         \"longformer : Pretrain + Fine-Tune\": response_cust_gs_v2,\n",
    "#         \"longformer : Fine-Tune\": response_gs,\n",
    "#         \"bag-of-word\": response_gs_bm\n",
    "#     }\n",
    "\n",
    "    \n",
    "#     CL=['r', 'g', 'b', 'c', 'y', 'darkorange', 'lime', 'grey','gold','bisque', 'lightseagreen', 'purple']\n",
    "#     bar_plot(data, colors=CL,total_width=.7, single_width=1,title=\"(MSR+Member Transcript)\",subtitle=\"Training Set \",axis_truncation=0.50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msgifsr",
   "language": "python",
   "name": "msgifsr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b12f997f133cc277d152bd66d30ab729e2a8cbd695c7765ccc1cb6177d1db4f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
