{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "import sys\n",
    "sys.path=list(set(sys.path))\n",
    "root_dir='/home/ec2-user/SageMaker/sequence-based-recommendation'\n",
    "model_name=\"NARM\"\n",
    "model_path=os.path.join(root_dir,model_name)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "import metric\n",
    "from utils import collate_fn\n",
    "from narm import NARM\n",
    "from dataset import load_data, RecSysDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NARM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=512, dataset_path='./YOOCHOOSE_data/yoochoose1_64/', embed_dim=50, hidden_size=100, n_items=37484, topk=20, valid_portion=0.1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset_path', default='./YOOCHOOSE_data/yoochoose1_64/', \n",
    "                        help='dataset directory path: datasets/amex/yoochoose1_4/yoochoose1_64')\n",
    "    \n",
    "    parser.add_argument('--n_items', type=int, default=37484, help='number of unique items. 37484 for yoochoose')\n",
    "    parser.add_argument('--batch_size', type=int, default=512, help='input batch size')\n",
    "    parser.add_argument('--hidden_size', type=int, default=100, help='hidden state size of gru module')\n",
    "    parser.add_argument('--embed_dim', type=int, default=50, help='the dimension of item embedding')\n",
    "    parser.add_argument('--topk', type=int, default=20, help='number of top score items selected for calculating recall and mrr metrics')\n",
    "    parser.add_argument('--valid_portion', type=float, default=0.1, help='split the portion of training set as validation set')\n",
    "    args,_ = parser.parse_known_args()\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 332873\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 36986\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "training batch                651        \n",
      "validation batch              73         \n",
      "test batch                    110        \n"
     ]
    }
   ],
   "source": [
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_64/'\n",
    "train, valid, test = load_data(args.dataset_path, valid_portion=args.valid_portion)\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader_yoochoose1_64 = DataLoader(train_data, batch_size = args.batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "valid_loader_yoochoose1_64 = DataLoader(valid_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "test_loader_yoochoose1_64 = DataLoader(test_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader_yoochoose1_64)))\n",
    "print('{:<30}{:<10,} '.format(\"validation batch\",len(valid_loader_yoochoose1_64)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader_yoochoose1_64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 5325970\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 591775\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "training batch                10,403     \n",
      "validation batch              1,156      \n",
      "test batch                    110        \n"
     ]
    }
   ],
   "source": [
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_4/'\n",
    "train, valid, test = load_data(args.dataset_path, valid_portion=args.valid_portion)\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader_yoochoose1_4 = DataLoader(train_data, batch_size = args.batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "valid_loader_yoochoose1_4 = DataLoader(valid_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "test_loader_yoochoose1_4 = DataLoader(test_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader_yoochoose1_4)))\n",
    "print('{:<30}{:<10,} '.format(\"validation batch\",len(valid_loader_yoochoose1_4)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader_yoochoose1_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_loader, model,criterion):\n",
    "    model.eval()\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "    losses=[]\n",
    "    with torch.no_grad():\n",
    "        for seq, target, lens in valid_loader:\n",
    "            seq = seq.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs = model(seq, lens)\n",
    "            loss = criterion(outputs, target)\n",
    "            logits = F.softmax(outputs, dim = 1)\n",
    "            recall, mrr = metric.evaluate(logits, target, k = args.topk)\n",
    "            recalls.append(recall)\n",
    "            mrrs.append(mrr)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_mrr = np.mean(mrrs)\n",
    "    mean_loss=np.mean(losses)\n",
    "    \n",
    "    return mean_recall, mean_mrr, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NARM(args.n_items, args.hidden_size, args.embed_dim, args.batch_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.6704, MRR@20: 0.2836\n"
     ]
    }
   ],
   "source": [
    "model_name='yoochoose1_64_latest_checkpoint.pth'\n",
    "model_path=os.path.join(os.getcwd(),\"NARM\", model_name)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "recall_v1, mrr_v1,loss_v1 = validate(test_loader_yoochoose1_64, model,criterion)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v1, args.topk, mrr_v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.6950, MRR@20: 0.2909\n"
     ]
    }
   ],
   "source": [
    "model_name='yoochoose1_4_latest_checkpoint.pth'\n",
    "model_path=os.path.join(os.getcwd(),\"NARM\", model_name)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "recall_v2, mrr_v2,loss_v2 = validate(test_loader_yoochoose1_4, model,criterion)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v2, args.topk, mrr_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 3182\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 354\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 305\n",
      "--------------------------------------------------\n",
      "training batch                50         \n",
      "validation batch              6          \n",
      "test batch                    5          \n",
      "\n",
      "Test: Recall@20: 0.6362, MRR@20: 0.5320\n"
     ]
    }
   ],
   "source": [
    "args.n_items=556\n",
    "args.batch_size=64\n",
    "args.dataset_path=\"./dataset/amex_explorepoi-poi_category/\"\n",
    "train, valid, test = load_data(args.dataset_path, valid_portion=args.valid_portion)\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader_amex = DataLoader(train_data, batch_size = args.batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "valid_loader_amex = DataLoader(valid_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "test_loader_amex = DataLoader(test_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader_amex)))\n",
    "print('{:<30}{:<10,} '.format(\"validation batch\",len(valid_loader_amex)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader_amex)))\n",
    "\n",
    "model = NARM(args.n_items, args.hidden_size, args.embed_dim, args.batch_size).to(device)\n",
    "\n",
    "model_name='amex_explorepoi-poi_category_latest_checkpoint.pth'\n",
    "model_path=os.path.join(os.getcwd(),\"NARM\", model_name)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "recall_v3, mrr_v3,loss_v3 = validate(test_loader_amex, model,criterion = nn.CrossEntropyLoss())\n",
    "print()\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v3, args.topk, mrr_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a081d_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall@20</th>\n",
       "      <th class=\"col_heading level0 col3\" >MRR@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a081d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a081d_row0_col0\" class=\"data row0 col0\" >NARM</td>\n",
       "      <td id=\"T_a081d_row0_col1\" class=\"data row0 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_a081d_row0_col2\" class=\"data row0 col2\" >67.04%</td>\n",
       "      <td id=\"T_a081d_row0_col3\" class=\"data row0 col3\" >28.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a081d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a081d_row1_col0\" class=\"data row1 col0\" >NARM</td>\n",
       "      <td id=\"T_a081d_row1_col1\" class=\"data row1 col1\" >yoochoose1_4</td>\n",
       "      <td id=\"T_a081d_row1_col2\" class=\"data row1 col2\" >69.50%</td>\n",
       "      <td id=\"T_a081d_row1_col3\" class=\"data row1 col3\" >29.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a081d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a081d_row2_col0\" class=\"data row2 col0\" >NARM</td>\n",
       "      <td id=\"T_a081d_row2_col1\" class=\"data row2 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_a081d_row2_col2\" class=\"data row2 col2\" >63.62%</td>\n",
       "      <td id=\"T_a081d_row2_col3\" class=\"data row2 col3\" >53.20%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdafc4c57c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df=pd.DataFrame()\n",
    "output_df[\"Model\"]=[\"NARM\"]*3\n",
    "output_df[\"Dataset\"]=[\"yoochoose1_64\",\"yoochoose1_4\",\"amex-poi-category\"]\n",
    "output_df[\"Recall@20\"]=[recall_v1,recall_v2,recall_v3]\n",
    "output_df[\"MRR@20\"]=[mrr_v1,mrr_v2,mrr_v3]\n",
    "output_df.style.format({'Recall@20':'{:.2%}','MRR@20':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path=list(set(sys.path))\n",
    "root_dir='/home/ec2-user/SageMaker/sequence-based-recommendation'\n",
    "old_model_name=\"NARM\"\n",
    "old_model_path=os.path.join(root_dir,old_model_name)\n",
    "sys.path=[x for x in sys.path if x !=old_model_path]\n",
    "\n",
    "model_name=\"SRGNN\"\n",
    "model_path=os.path.join(root_dir,model_name)\n",
    "sys.path.append(model_path)\n",
    "\n",
    "from srgnn import SRGNN\n",
    "from collate import (collate_fn_factory, seq_to_session_graph)\n",
    "import metric\n",
    "from dataset import load_data,RecSysDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(batch, device):\n",
    "    inputs, labels = batch\n",
    "    # inputs, labels = batch\n",
    "    inputs_gpu  = [x.to(device) for x in inputs]\n",
    "    labels_gpu  = labels.to(device)\n",
    "   \n",
    "    return inputs_gpu, labels_gpu \n",
    "\n",
    "def validate(valid_loader, model,device):\n",
    "    model.eval()\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "    losses=[]\n",
    "    with torch.no_grad():\n",
    "        for step, batch in tqdm(enumerate(valid_loader), total=len(valid_loader),position=0,leave=True):\n",
    "            inputs, labels = prepare_batch(batch, device)\n",
    "            outputs = model(*inputs)\n",
    "            # loss = criterion(outputs, labels)\n",
    "            loss = nn.functional.nll_loss(outputs, labels)\n",
    "            logits = F.softmax(outputs, dim = 1)\n",
    "            recall, mrr = metric.evaluate(logits, labels, k = args.topk)\n",
    "            recalls.append(recall)\n",
    "            mrrs.append(mrr)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_mrr = np.mean(mrrs)\n",
    "    mean_loss=np.mean(losses)\n",
    "    \n",
    "    return mean_recall, mean_mrr, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=512, dataset_dir='../YOOCHOOSE_data/yoochoose1_64/', embedding_dim=256, feat_drop=0.1, n_items=37484, num_layers=1, num_workers=0, seed=101, topk=20, valid_split=0.1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        '--dataset-dir', default='../YOOCHOOSE_data/yoochoose1_64/', help='the dataset directory'\n",
    "    )\n",
    "    parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "            help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "    parser.add_argument(\n",
    "    '--batch-size', type=int, default=512, help='the batch size for training'\n",
    "    )\n",
    "\n",
    "    parser.add_argument('--n_items', type=int, default=37484, help='number of unique items. 37484 for yoochoose')\n",
    "    parser.add_argument('--embedding-dim', type=int, default=256, help='the embedding size')\n",
    "    parser.add_argument('--num-layers', type=int, default=1, help='the number of layers')\n",
    "    parser.add_argument('--feat-drop', type=float, default=0.1, help='the dropout ratio for features')\n",
    "    parser.add_argument(\n",
    "    '--valid-split',\n",
    "    type=float,\n",
    "    default=0.1,\n",
    "    help='the fraction for the validation set',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--num-workers',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help='the number of processes to load the input graphs',\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--topk', \n",
    "        type=int, \n",
    "        default=20, \n",
    "        help='number of top score items selected for calculating recall and mrr metrics',\n",
    "    )\n",
    "\n",
    "    args,_= parser.parse_known_args()\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 332873\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 36986\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "training batch                651        \n",
      "validation batch              73         \n",
      "test batch                    110        \n"
     ]
    }
   ],
   "source": [
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_64/'\n",
    "train, valid, test = load_data(args.dataset_path, valid_portion=args.valid_split)\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader_yoochoose1_64 = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "valid_loader_yoochoose1_64 = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(valid_data)\n",
    ")\n",
    "\n",
    "test_loader_yoochoose1_64 = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader_yoochoose1_64)))\n",
    "print('{:<30}{:<10,} '.format(\"validation batch\",len(valid_loader_yoochoose1_64)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader_yoochoose1_64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 5325970\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 591775\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 55898\n",
      "--------------------------------------------------\n",
      "training batch                10,403     \n",
      "validation batch              1,156      \n",
      "test batch                    110        \n"
     ]
    }
   ],
   "source": [
    "args.dataset_path='./YOOCHOOSE_data/yoochoose1_4/'\n",
    "train, valid, test = load_data(args.dataset_path, valid_portion=args.valid_split)\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader_yoochoose1_4 = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "valid_loader_yoochoose1_4 = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(valid_data)\n",
    ")\n",
    "\n",
    "test_loader_yoochoose1_4 = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader_yoochoose1_4)))\n",
    "print('{:<30}{:<10,} '.format(\"validation batch\",len(valid_loader_yoochoose1_4)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader_yoochoose1_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 3182\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 354\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 305\n",
      "--------------------------------------------------\n",
      "training batch                50         \n",
      "validation batch              6          \n",
      "test batch                    5          \n"
     ]
    }
   ],
   "source": [
    "args.n_items=556\n",
    "args.batch_size=64\n",
    "args.dataset_path=\"./dataset/amex_explorepoi-poi_category/\"\n",
    "train, valid, test = load_data(args.dataset_path, valid_portion=args.valid_split)\n",
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "\n",
    "collate_fn = collate_fn_factory(seq_to_session_graph)\n",
    "train_loader_amex = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(train_data)\n",
    ")\n",
    "\n",
    "valid_loader_amex = DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=args.batch_size,\n",
    "    # shuffle=True,\n",
    "    # drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    sampler=SequentialSampler(valid_data)\n",
    ")\n",
    "\n",
    "test_loader_amex = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=args.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print('{:<30}{:<10,} '.format(\"training batch\",len(train_loader_amex)))\n",
    "print('{:<30}{:<10,} '.format(\"validation batch\",len(valid_loader_amex)))\n",
    "print('{:<30}{:<10,} '.format(\"test batch\",len(test_loader_amex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SRGNN(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:22<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.6786, MRR@20: 0.2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name='yoochoose1_64_latest_checkpoint.pth'\n",
    "model_path=os.path.join(os.getcwd(),\"SRGNN\", model_name)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "recall_v1, mrr_v1,loss_v1 = validate(test_loader_yoochoose1_64, model,device)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v1, args.topk, mrr_v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:20<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.5924, MRR@20: 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name='yoochoose1_4_latest_checkpoint.pth'\n",
    "model_path=os.path.join(os.getcwd(),\"SRGNN\", model_name)\n",
    "ckpt = torch.load(model_path)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "recall_v2, mrr_v2,loss_v2 = validate(test_loader_yoochoose1_4, model,device)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v2, args.topk, mrr_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 35.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.6265, MRR@20: 0.2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name='amex_explorepoi-poi_category_latest_checkpoint.pth'\n",
    "model_path=os.path.join(os.getcwd(),\"SRGNN\", model_name)\n",
    "ckpt = torch.load(model_path)\n",
    "\n",
    "args.n_items=556\n",
    "model = SRGNN(args.n_items, args.embedding_dim, args.num_layers, feat_drop=args.feat_drop).to(device)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "recall_v3, mrr_v3,loss_v3 = validate(test_loader_amex, model,device)\n",
    "print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall_v3, args.topk, mrr_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8fab3_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Dataset</th>\n",
       "      <th class=\"col_heading level0 col2\" >Recall@20</th>\n",
       "      <th class=\"col_heading level0 col3\" >MRR@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8fab3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8fab3_row0_col0\" class=\"data row0 col0\" >NARM</td>\n",
       "      <td id=\"T_8fab3_row0_col1\" class=\"data row0 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_8fab3_row0_col2\" class=\"data row0 col2\" >67.04%</td>\n",
       "      <td id=\"T_8fab3_row0_col3\" class=\"data row0 col3\" >28.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fab3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8fab3_row1_col0\" class=\"data row1 col0\" >NARM</td>\n",
       "      <td id=\"T_8fab3_row1_col1\" class=\"data row1 col1\" >yoochoose1_4</td>\n",
       "      <td id=\"T_8fab3_row1_col2\" class=\"data row1 col2\" >69.50%</td>\n",
       "      <td id=\"T_8fab3_row1_col3\" class=\"data row1 col3\" >29.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fab3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8fab3_row2_col0\" class=\"data row2 col0\" >NARM</td>\n",
       "      <td id=\"T_8fab3_row2_col1\" class=\"data row2 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_8fab3_row2_col2\" class=\"data row2 col2\" >63.62%</td>\n",
       "      <td id=\"T_8fab3_row2_col3\" class=\"data row2 col3\" >53.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fab3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8fab3_row3_col0\" class=\"data row3 col0\" >SRGNN</td>\n",
       "      <td id=\"T_8fab3_row3_col1\" class=\"data row3 col1\" >yoochoose1_64</td>\n",
       "      <td id=\"T_8fab3_row3_col2\" class=\"data row3 col2\" >67.86%</td>\n",
       "      <td id=\"T_8fab3_row3_col3\" class=\"data row3 col3\" >29.25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fab3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8fab3_row4_col0\" class=\"data row4 col0\" >SRGNN</td>\n",
       "      <td id=\"T_8fab3_row4_col1\" class=\"data row4 col1\" >yoochoose1_4</td>\n",
       "      <td id=\"T_8fab3_row4_col2\" class=\"data row4 col2\" >59.24%</td>\n",
       "      <td id=\"T_8fab3_row4_col3\" class=\"data row4 col3\" >23.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fab3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_8fab3_row5_col0\" class=\"data row5 col0\" >SRGNN</td>\n",
       "      <td id=\"T_8fab3_row5_col1\" class=\"data row5 col1\" >amex-poi-category</td>\n",
       "      <td id=\"T_8fab3_row5_col2\" class=\"data row5 col2\" >62.65%</td>\n",
       "      <td id=\"T_8fab3_row5_col3\" class=\"data row5 col3\" >27.09%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd93479cd60>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempt={\"Model\":[\"SRGNN\"]*3, \"Dataset\":[\"yoochoose1_64\",\"yoochoose1_4\",\"amex-poi-category\"],\n",
    "      \"Recall@20\":[recall_v1,recall_v2,recall_v3],\"MRR@20\":[mrr_v1,mrr_v2,mrr_v3]}\n",
    "tempt=pd.DataFrame(tempt)\n",
    "output_df=output_df.append(tempt,ignore_index=True)\n",
    "output_df.style.format({'Recall@20':'{:.2%}','MRR@20':'{:.2%}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SRGNN",
   "language": "python",
   "name": "srgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b12f997f133cc277d152bd66d30ab729e2a8cbd695c7765ccc1cb6177d1db4f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
